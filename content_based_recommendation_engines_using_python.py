# -*- coding: utf-8 -*-
"""Content Based Recommendation Engines using Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_mj2xs8YGYEjWCj7PNnoS0fg3YtzOpNJ

## Building a Movie Content Based Recommendation System

![image.png](attachment:image.png)
"""

import pandas as pd
import numpy as np

#https://www.kaggle.com/tmdb/tmdb-movie-metadata
# credits = pd.read_csv("tmdb_5000_credits.csv")

movies_df = pd.read_csv("tmdb_5000_movies.csv")

# credits.head()

movies_df.head()



# print("Credits:",credits.shape)
print("Movies Dataframe:",movies_df.shape)

credits_column_renamed = movies_df.rename(index=str, columns={"movie_id": "id"})
movies_df_merge = movies_df.merge(credits_column_renamed, on='id')
movies_df_merge.head()

print(movies_df_merge.columns)

# Drop only unnecessary columns, keeping the necessary ones for weighted average calculation
columns_to_drop = [
    'budget_x', 'budget_y',
    'production_companies_x', 'production_companies_y', 'release_date_x',
    'release_date_y', 'overview_y'  # Only drop overview_y, keep overview_x
]

# Apply the drop operation
movies_cleaned_df = movies_df_merge.drop(columns=columns_to_drop)

# Check if 'vote_average' and 'vote_count' exist in the remaining columns
# If not, assign these back using available data

if 'vote_average' not in movies_cleaned_df.columns:
    movies_cleaned_df['vote_average'] = movies_df_merge['vote_average_x']

if 'vote_count' not in movies_cleaned_df.columns:
    movies_cleaned_df['vote_count'] = movies_df_merge['vote_count_x']

movies_cleaned_df.info()

"""### Content Based Recommendation System

Now lets make a recommendations based on the movieâ€™s plot summaries given in the overview column. So if our user gives us a movie title, our goal is to recommend movies that share similar plot summaries.
"""

movies_cleaned_df.head()['overview_x']

from sklearn.feature_extraction.text import TfidfVectorizer


tfv = TfidfVectorizer(min_df=3,  max_features=None,
            strip_accents='unicode', analyzer='word',token_pattern=r'\w{1,}',
            ngram_range=(1, 3),
            stop_words = 'english')

# Filling NaNs with empty string
movies_cleaned_df['overview_y'] = movies_cleaned_df['overview_x'].fillna('')

# Verify the DataFrame and its columns
print(movies_cleaned_df.columns)

# Print the first few rows to inspect
print(movies_cleaned_df.head())

# Ensure 'overview' is a column in movies_cleaned_df
if 'overview_x' not in movies_cleaned_df.columns:
    raise ValueError("The 'overview' column is missing from the DataFrame.")

# Fitting the TF-IDF on the 'overview' text
tfv_matrix = tfv.fit_transform(movies_cleaned_df['overview_y'])

tfv_matrix

tfv_matrix.shape

from sklearn.metrics.pairwise import sigmoid_kernel

# Compute the sigmoid kernel
sig = sigmoid_kernel(tfv_matrix, tfv_matrix)

sig[0]

# Reverse mapping of indices and movie titles
indices = pd.Series(movies_cleaned_df.index, index=movies_cleaned_df['original_title_x']).drop_duplicates()

indices

indices['Newlyweds']

sig[4799]

list(enumerate(sig[indices['Newlyweds']]))

sorted(list(enumerate(sig[indices['Newlyweds']])), key=lambda x: x[1], reverse=True)

def give_rec(title, sig=sig):
    # Get the index corresponding to original_title
    idx = indices[title]

    # Get the pairwsie similarity scores
    sig_scores = list(enumerate(sig[idx]))

    # Sort the movies
    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)

    # Scores of the 10 most similar movies
    sig_scores = sig_scores[1:11]

    # Movie indices
    movie_indices = [i[0] for i in sig_scores]

    # Top 10 most similar movies
    return movies_cleaned_df['original_title_x'].iloc[movie_indices]

# Testing our content-based recommendation system with the seminal film Spy Kids
give_rec('Avatar')

import matplotlib.pyplot as plt
import seaborn as sns

# Proceed with calculating the weighted average
C = movies_cleaned_df['vote_average'].mean()
m = movies_cleaned_df['vote_count'].quantile(0.70)

def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']
    return (v/(v+m) * R) + (m/(m+v) * C)

movies_cleaned_df['weighted_average'] = movies_cleaned_df.apply(weighted_rating, axis=1)

# Proceed with the plotting code as before
weight_average = movies_cleaned_df.sort_values('weighted_average', ascending=False)

plt.figure(figsize=(12, 6))
axis1 = sns.barplot(x=weight_average['weighted_average'].head(10),
                    y=weight_average['original_title_x'].head(10),
                    data=weight_average)

plt.xlim(4, 10)
plt.title('Best Movies by Average Votes', weight='bold')
plt.xlabel('Weighted Average Score', weight='bold')
plt.ylabel('Movie Title', weight='bold')
plt.savefig('best_movies.png')
plt.show()